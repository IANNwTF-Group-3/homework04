{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# disable compiler warnings\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "# imports \n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from typing import List\n",
    "import datetime\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mnist from tensorflow_datasets\n",
    "mnist = tfds.load(\"mnist\", split =[\"train\",\"test\"], as_supervised=True)\n",
    "train_ds = mnist[0]\n",
    "val_ds = mnist[1]\n",
    "\n",
    "# write function to create the dataset that we want\n",
    "def preprocess(data, batch_size, subtask):\n",
    "    # FIRST STEP\n",
    "    # image should be float\n",
    "    data = data.map(lambda x, t: (tf.cast(x, float), t))\n",
    "    # image should be flattened\n",
    "    data = data.map(lambda x, t: (tf.reshape(x, (-1,)), t))\n",
    "    # image vector will here have values between -1 and 1\n",
    "    data = data.map(lambda x,t: ((x/128.)-1., t))\n",
    "    # we want to have two mnist images in each example\n",
    "    # this leads to a single example being ((x1,y1),(x2,y2))\n",
    "    zipped_ds = tf.data.Dataset.zip((data.shuffle(2000), \n",
    "                                     data.shuffle(2000)))\n",
    "\n",
    "\n",
    "    # SECOND STEP\n",
    "    # a + b >= 5 is a boolean classification -> one output perceptron, BinaryCrossEntropy loss function\n",
    "    # y_true: 0 oder 1, y_pred : [0,1]\n",
    "    # \n",
    "    # a - b = y choose a number for {-9, -8, ..., 8, 9} softmax from 19 possibilities, CategoricalCrossEntropy loss function\n",
    "    # y_true: one-hot-vector size 19, y_pred : one-hot-vector size 19 softmax\n",
    "\n",
    "    if (subtask == 1):\n",
    "        # target is 1 if value1 + value2 >= 5 else 0\n",
    "        zipped_ds = zipped_ds.map(lambda x1, x2: (x1[0], x2[0], x1[1] + x2[1] >= 5))\n",
    "        # transform boolean target to int\n",
    "        zipped_ds = zipped_ds.map(lambda x1, x2, t: (x1,x2, tf.cast(t, tf.int32)))\n",
    "    elif (subtask == 2):\n",
    "        # target is value of label1 - label2\n",
    "        zipped_ds= zipped_ds.map(lambda x1, x2: (x1[0], x2[0], x1[1] - x2[1]))\n",
    "\n",
    "\n",
    "    # batch the dataset\n",
    "    zipped_ds = zipped_ds.batch(batch_size)\n",
    "    # prefetch\n",
    "    zipped_ds = zipped_ds.prefetch(tf.data.AUTOTUNE)\n",
    "    return zipped_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model of our network\n",
    "class TwinMNISTModel(tf.keras.Model):\n",
    "\n",
    "    # constructor\n",
    "    def __init__(self, optimizer, subtask):\n",
    "        super().__init__()\n",
    "        # inherit functionality from parent class\n",
    "\n",
    "        # optimizer, loss function and metrics\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "        # layers to be used\n",
    "        # feed 28*28 pixels into this layer, spits out 0-9 one-hot-vector\n",
    "        self.dense1 = tf.keras.layers.Dense(32, activation=tf.nn.relu)\n",
    "\n",
    "        # feed in 0-9 one-hot-vector, spits out softmax representation\n",
    "        self.dense2 = tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "\n",
    "        # a + b >= 5 ? gets in two softmax representations of a digit, spits out 0 = False, 1 = True\n",
    "        if subtask == 1:\n",
    "            self.out_layer = tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
    "            self.loss_function = tf.keras.losses.BinaryCrossentropy()\n",
    "            self.metrics_list = [tf.keras.metrics.BinaryAccuracy(name=\"Accuracy\"),\n",
    "                                 tf.keras.metrics.Mean(name=\"loss\")]\n",
    "                                 \n",
    "        # a - b = y, gets in two softmax representations of a digit, spits out a value\n",
    "        else:\n",
    "            self.out_layer = tf.keras.layers.Dense(1, activation=None)\n",
    "            self.loss_function = tf.keras.losses.MeanSquaredError()\n",
    "            self.metrics_list = [tf.keras.metrics.MeanSquaredError(name=\"Accuracy\"),\n",
    "                                 tf.keras.metrics.Mean(name=\"loss\")]\n",
    "        \n",
    "        \n",
    "    # call method\n",
    "    @tf.function\n",
    "    def call(self, images, training=False):\n",
    "        # get images\n",
    "        img1, img2 = images\n",
    "\n",
    "        # let image go through first two layers, spits out one-hot-vector representing the number seen\n",
    "        img1_x = self.dense1(img1)\n",
    "        img1_x = self.dense2(img1_x)\n",
    "        \n",
    "        # same with second image\n",
    "        img2_x = self.dense1(img2)\n",
    "        img2_x = self.dense2(img2_x)\n",
    "\n",
    "        # concat the one-hot-vectors\n",
    "        combined_x = tf.concat([img1_x, img2_x ], axis=1)\n",
    "\n",
    "        # concatenated one hot vector into the output layer, squeeze the axis with dim=1\n",
    "        return tf.squeeze(self.out_layer(combined_x), axis=None, name=None)\n",
    "\n",
    "\n",
    "\n",
    "    # 3. metrics property\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return self.metrics_list\n",
    "        # return a list with all metrics in the model\n",
    "\n",
    "\n",
    "\n",
    "    # 4. reset all metrics objects\n",
    "    def reset_metrics(self):\n",
    "        for metric in self.metrics:\n",
    "            metric.reset_states()\n",
    "\n",
    "\n",
    "\n",
    "    # train_step method\n",
    "    def train_step(self, data):\n",
    "        img1, img2, label = data\n",
    "        \n",
    "        # compute output and loss, train the variables\n",
    "        with tf.GradientTape() as tape:\n",
    "            output = self((img1, img2), training=True)\n",
    "            loss = self.loss_function(label, output)\n",
    "            \n",
    "        # update trainable variables\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "\n",
    "        # rounds output with bankers rounding\n",
    "        function_to_map = lambda x: tf.cast(tf.math.round(x), tf.float32)\n",
    "        output = tf.map_fn(function_to_map, output)\n",
    "\n",
    "        # update metrics\n",
    "        self.metrics[0].update_state(output, label)\n",
    "        self.metrics[1].update_state(loss)\n",
    "        \n",
    "        # return a dict with metric information\n",
    "        return {m.name : m.result() for m in self.metrics_list}\n",
    "\n",
    "\n",
    "\n",
    "    # test_step method\n",
    "    def test_step(self, data):\n",
    "        img1, img2, label = data\n",
    "\n",
    "        # compute output and loss, without training\n",
    "        output = self((img1, img2), training=False)\n",
    "        loss = self.loss_function(label, output)\n",
    "\n",
    "        # rounds output with bankers rounding\n",
    "        function_to_map = lambda x: tf.cast(tf.math.round(x), tf.float32)\n",
    "        output = tf.map_fn(function_to_map, output)\n",
    "        \n",
    "        \n",
    "        # update metrics\n",
    "        self.metrics[0].update_state(output, label)\n",
    "        self.metrics[1].update_state(loss)\n",
    "\n",
    "        #print(\"out: \", output, \"\\n label: \", label, \"\\naccuracy: \", self.metrics[0].result())\n",
    "\n",
    "        # return a dict with metric information \n",
    "        return {m.name : m.result() for m in self.metrics_list}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a summary writer to log data\n",
    "\n",
    "- use tf.summary.create_file_writer(log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_name = \"Run-42\"\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "train_log_path = f\"logs/{config_name}/{current_time}/train\"\n",
    "val_log_path = f\"logs//{config_name}/{current_time}/val\"\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_path)\n",
    "val_summary_writer = tf.summary.create_file_writer(val_log_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write a training loop function\n",
    "\n",
    "Arguments: \n",
    " - the model to train, \n",
    " - the data to train on, \n",
    " - the data to test on, \n",
    " - how many epochs to train, \n",
    " - the train summary writer object to use for logging\n",
    " - the validation summary writer object to use for logging\n",
    " - a path to save trained model weights to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trains the model by iterating through the dataset and applying training_step method epochs time\n",
    "def training_loop(model, train_ds, epochs, train_summary_writer):\n",
    "    # iterate over epochs\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"epoch: {epoch}\")\n",
    "\n",
    "        # train steps on all batches in the training data\n",
    "        for (img1, img2, label) in train_ds:\n",
    "            metrics = model.train_step((img1, img2, label))\n",
    "            \n",
    "            # keep data in summary with metrics\n",
    "            with train_summary_writer.as_default():\n",
    "                for metric in model.metrics_list:\n",
    "                    tf.summary.scalar(f\"{metric.name}\", metric.result(), step=epoch)\n",
    "        \n",
    "        # print current metric values and reset the metrics\n",
    "        print([f\"{key} : {value.numpy()}\" for (key, value ) in metrics.items()])\n",
    "        model.reset_metrics()\n",
    "\n",
    "\n",
    "\n",
    "# tests overall performance of model\n",
    "def test_loop(model, test_ds, val_summary_writer):\n",
    "    # test steps on every item in test dataset\n",
    "    for (img1, img2, label) in test_ds:\n",
    "        metrics = model.test_step((img1, img2, label))\n",
    "        \n",
    "        # keep data with metrics\n",
    "        with val_summary_writer.as_default():\n",
    "            for metric in model.metrics_list:\n",
    "                tf.summary.scalar(f\"{metric.name}\", metric.result(), step=1)\n",
    "    \n",
    "    #print current metric values and reset the metrics\n",
    "    print([f\"{key} : {value.numpy()}\" for (key, value ) in metrics.items()])\n",
    "    model.reset_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the training loop function to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 784) (32, 784) (32,)\n",
      "(32, 784) (32, 784) (32,)\n",
      "testing beforehand subtask 1 ...\n",
      "['Accuracy : 0.8407999873161316', 'loss : 0.6022011041641235']\n",
      "training subtask 1 ...\n",
      "\n",
      "epoch: 0\n",
      "['Accuracy : 0.8753166794776917', 'loss : 0.34077683091163635']\n",
      "epoch: 1\n",
      "['Accuracy : 0.9193999767303467', 'loss : 0.22551698982715607']\n",
      "epoch: 2\n",
      "['Accuracy : 0.9398833513259888', 'loss : 0.18648956716060638']\n",
      "testing subtask 1 ...\n",
      "\n",
      "['Accuracy : 0.9416999816894531', 'loss : 0.17586058378219604']\n",
      "testing beforehand subtask 2 ...\n",
      "['Accuracy : 16.859325408935547', 'loss : 16.89692497253418']\n",
      "training subtask 2 ...\n",
      "\n",
      "epoch: 0\n",
      "['Accuracy : 10.224833488464355', 'loss : 10.166271209716797']\n",
      "epoch: 1\n",
      "['Accuracy : 4.849050045013428', 'loss : 4.756966590881348']\n",
      "epoch: 2\n",
      "['Accuracy : 2.7425167560577393', 'loss : 2.6783344745635986']\n",
      "epoch: 3\n",
      "['Accuracy : 2.0313167572021484', 'loss : 1.9503564834594727']\n",
      "epoch: 4\n",
      "['Accuracy : 1.6733332872390747', 'loss : 1.613296389579773']\n",
      "epoch: 5\n",
      "['Accuracy : 1.4556666612625122', 'loss : 1.3844228982925415']\n",
      "epoch: 6\n",
      "['Accuracy : 1.3280333280563354', 'loss : 1.2648977041244507']\n",
      "testing subtask 2...\n",
      "\n",
      "['Accuracy : 1.616713285446167', 'loss : 1.5684497356414795']\n"
     ]
    }
   ],
   "source": [
    "# get preprocessed data for both subtasks\n",
    "train_ds_sub1 = preprocess(train_ds, batch_size=32, subtask=1) #train_ds.apply(preprocess)\n",
    "val_ds_sub1 = preprocess(val_ds, batch_size=32, subtask=1) #val_ds.apply(preprocess)\n",
    "\n",
    "train_ds_sub2 = preprocess(train_ds, batch_size=32, subtask=2) #train_ds.apply(preprocess)\n",
    "val_ds_sub2 = preprocess(val_ds, batch_size=32, subtask=2) #val_ds.apply(preprocess)\n",
    "\n",
    "\n",
    "# check the contents of the dataset\n",
    "for img1, img2, label in train_ds_sub1.take(1):\n",
    "    print(img1.shape, img2.shape, label.shape)\n",
    "    #print(img1, img2, label)\n",
    "\n",
    "for img1, img2, label in train_ds_sub2.take(1):\n",
    "    print(img1.shape, img2.shape, label.shape)\n",
    "    #print(img1, img2, label)\n",
    "\n",
    "\"\"\" SUBTASK 1\"\"\"\n",
    "model = TwinMNISTModel(tf.keras.optimizers.Adam(), subtask=1)\n",
    "print(f\"testing beforehand subtask 1 ...\")\n",
    "test_loop(model,\n",
    "        test_ds=val_ds_sub1,\n",
    "        val_summary_writer=val_summary_writer)\n",
    "        \n",
    "print(f\"training subtask 1 ...\\n\")\n",
    "training_loop(model,\n",
    "              train_ds=train_ds_sub1,\n",
    "              epochs=3, \n",
    "              train_summary_writer=train_summary_writer)\n",
    "\n",
    "print(f\"testing subtask 1 ...\\n\")\n",
    "test_loop(model,\n",
    "        test_ds=val_ds_sub1,\n",
    "        val_summary_writer=val_summary_writer)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" SUBTASK 2 \"\"\"\n",
    "model = TwinMNISTModel(tf.keras.optimizers.Adam(), subtask=2)\n",
    "print(f\"testing beforehand subtask 2 ...\")\n",
    "test_loop(model,\n",
    "        test_ds=val_ds_sub2,\n",
    "        val_summary_writer=val_summary_writer)\n",
    "\n",
    "print(f\"training subtask 2 ...\\n\")\n",
    "training_loop(model,\n",
    "              train_ds=train_ds_sub2,\n",
    "              epochs=7, \n",
    "              train_summary_writer=train_summary_writer)\n",
    "\n",
    "print(f\"testing subtask 2...\\n\")\n",
    "test_loop(model,\n",
    "        test_ds=val_ds_sub2,\n",
    "        val_summary_writer=val_summary_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-8a781e9e406ae838\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-8a781e9e406ae838\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# open the tensorboard logs\n",
    "%tensorboard --logdir logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('iannwtf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "9b8c50c33561e7eff6eeea8f3e10c61ef76237379e0ac0cad7905faedae1c269"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
