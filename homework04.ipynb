{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Task 02.01\n",
    "Load the MNIST dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\plo-k\\tensorflow_datasets\\mnist\\3.0.1...\n"
     ]
    },
    {
     "data": {
      "text/plain": "Dl Completed...: 0 url [00:00, ? url/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aeb372c5dc984a83a8a89148a760d11f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Dl Size...: 0 MiB [00:00, ? MiB/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a6e89665ff944dff9d9a11b3d6d40065"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Extraction completed...: 0 file [00:00, ? file/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c87046da15d14bfa9be1c06ae9a011bb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating splits...:   0%|          | 0/2 [00:00<?, ? splits/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "05f1845570a949f3b7ff9e80d308819a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating train examples...: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dd20a178516e4262a78bbfc51c27ed1f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Shuffling C:\\Users\\plo-k\\tensorflow_datasets\\mnist\\3.0.1.incompleteQASVW2\\mnist-train.tfrecord*...:   0%|     …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "99dd41cc834b44d6ba24c8af7457dfba"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating test examples...: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "455c4e832b5843a5a5501af30bf756e2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Shuffling C:\\Users\\plo-k\\tensorflow_datasets\\mnist\\3.0.1.incompleteQASVW2\\mnist-test.tfrecord*...:   0%|      …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2186d87738b44cea8cd9b4fb380f7157"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset mnist downloaded and prepared to C:\\Users\\plo-k\\tensorflow_datasets\\mnist\\3.0.1. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "(train_ds, test_ds ), ds_info = tfds.load('mnist', split=['train', 'test'] , as_supervised = True , with_info = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Task 02.02\n",
    "Prepare the datasets."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "\n",
    "def prepare_dataset(data: tf.data.Dataset, target_fn: Callable[[float, float], float]) -> tf.data.Dataset:\n",
    "    \"\"\"\n",
    "    Prepared the MNIST dataset as two images. The label gets determined via the given function.\n",
    "    :param data: MNIST dataset\n",
    "    :param target_fn: Function to calculate the label of an image pair\n",
    "    :return: Prepared dataset\n",
    "    \"\"\"\n",
    "    # Convert image pixels from uint8 to float32\n",
    "    data = data.map(lambda image, label: (tf.cast(image, tf.float32), label))\n",
    "    # Flatten the image to 1D\n",
    "    data = data.map(lambda image, label: (tf.reshape(image, [-1]), label))\n",
    "    # Map pixel values to number between -1 and 1\n",
    "    data = data.map(lambda image, label: (image / 128. - 1, label))\n",
    "    # Create data pairs of two random dataset elements\n",
    "    zipped_ds = tf.data.Dataset.zip((data.shuffle(2000), data.shuffle(2000)))\n",
    "    # Generate labels according to the given target function\n",
    "    zipped_ds = zipped_ds.map(lambda first, second: (first[0], second[0], target_fn(first[1], second[1])))\n",
    "\n",
    "    zipped_ds = zipped_ds.cache()\n",
    "    zipped_ds = zipped_ds.shuffle(2000)\n",
    "    zipped_ds = zipped_ds.batch(32)\n",
    "    zipped_ds = zipped_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return zipped_ds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Task 3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define universal calculator model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class MnistCalculatorModel(tf.keras.Model):\n",
    "    def __init__(self, output_size: int, optimizer: tf.keras.optimizers.Optimizer, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.metrics_list = [tf.keras.metrics.BinaryAccuracy(),\n",
    "                             tf.keras.metrics.Mean(name=\"loss\")]\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_function = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "        self.number_detection_layer = tf.keras.layers.Dense(32, activation=tf.nn.relu)\n",
    "        self.calculation_layer = tf.keras.layers.Dense(10)\n",
    "        self.out_layer = tf.keras.layers.Dense(output_size, activation=tf.nn.sigmoid)\n",
    "\n",
    "\n",
    "    def call(self, images, training=False):\n",
    "        img1, img2 = images\n",
    "\n",
    "        img1_x = self.number_detection_layer(img1)\n",
    "        img2_x = self.number_detection_layer(img2)\n",
    "\n",
    "        combined_x = tf.concat([img1_x, img2_x], axis=1)\n",
    "        return self.out_layer(combined_x)\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return self.metrics_list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create training method"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class Subtask(Enum):\n",
    "    SUM_GREATER_5 = 0,\n",
    "    SUBTRACTION_EQUALS = 1\n",
    "\n",
    "def is_sum_greater_equals_x(x):\n",
    "    return lambda a, b: a + b >= x\n",
    "\n",
    "def subtract(a, b):\n",
    "    return tf.one_hot(a - b, 10)\n",
    "\n",
    "def train(subtask: Subtask, optimizer: tf.keras.optimizers.Optimizer):\n",
    "    # Define variables depending on subtask\n",
    "    target_fn = subtract if subtask == Subtask.SUBTRACTION_EQUALS else is_sum_greater_equals_x(5)\n",
    "    output_size = 10 if subtask == Subtask.SUBTRACTION_EQUALS else 1\n",
    "\n",
    "    train_data = train_ds.apply(lambda data: prepare_dataset(data, target_fn))\n",
    "    test_data = test_ds.apply(lambda data: prepare_dataset(data, target_fn))\n",
    "\n",
    "    model = MnistCalculatorModel(output_size, tf.keras.optimizers.Adam())\n",
    "\n",
    "    epoch_loss_agg = []\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    for epoch in range(1000):\n",
    "        for (img1, img2, target) in train_data:\n",
    "            with tf.GradientTape() as tape:\n",
    "                prediction = model((img1, img2), training=True)\n",
    "                loss = tf.losses.MeanSquaredError(target, prediction)\n",
    "            gradients = tape.gradient(loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "            epoch_loss_agg .append(loss)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
